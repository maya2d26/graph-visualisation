from itertools import combinations
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
from datetime import datetime
import os
import re
import time

import data.generate as gen

GRAPH_FOLDER = "../data/graphs" 
POS_FOLDER = "../data/positions" 

def final_pos_to_csv(g, folder = POS_FOLDER):
    """Saves the positional data of the graph to the \"final_pos.csv\".

    The csv's columns are id, type, algorithm and pos_dict"""
    # read the position df
    pos_df = pd.read_csv(f"{folder}/final_pos.csv",sep=";")
    
    # construct dictionary for node positions
    pos_dict = {}
    for node in g.nodes:
        pos_dict[node] = g.nodes[node]['pos']
    id = g.graph['id']
    type = g.graph['type']
    # if the type is star or random, the positions weren't generated by an algorithm
    if type != 'random':
        algorithm = type
    else:
        algorithm = g.graph['algorithm']

    # remove the previuous position if there was one
    pos_df = pos_df[~(pos_df['id']==id)]

    # create new row
    new_pos = pd.Series({'id':id, 'type':type, 'algorithm':algorithm, 'pos_dict':pos_dict})

    # add to df
    pos_df = pd.concat([pos_df, new_pos.to_frame().T], ignore_index=True)
    pos_df.to_csv(f"{folder}/final_pos.csv",index=False, sep=";")

def visualise(g, figsize = (8,8), file = None):
    """Visualises the graph
    :param g: the graph"""
    # get positional data
    pos = {node: g.nodes[node]['pos'] for node in g.nodes}
    fig = plt.figure(figsize=figsize)
    # illustrate graph 
    nx.draw(g, pos=pos,node_size = 200, ax = plt.gca())
    if file:
        plt.savefig(file)
    plt.show()

def add_final_pos(G, algorithm, positions):
    G.graph['algorithm'] = algorithm
    for node, pos in zip(G.nodes(),positions):
        G.nodes[node]['pos'] = tuple(pos)
    final_pos_to_csv(G)
    return G
    
def calculate_fr(G):
    pos = fruchterman_reingold(G)
    add_final_pos(G, "spring", pos)


def fruchterman_reingold(
    G, k=None, pos=None, center=None, iterations=1000, threshold=1e-4, dim=2, seed=7
):
    # Preprocessing
    # random seed
    seed = np.random.RandomState(seed)
    # center
    if center is None:
        center = np.zeros(dim)
    else:
        center = np.asarray(center)
    # pos
    if pos is not None:
        # Determine size of existing domain to adjust initial positions
        dom_size = max(coord for pos_tup in pos.values() for coord in pos_tup)
        if dom_size == 0:
            dom_size = 1
        pos_arr = seed.rand(len(G), dim) * dom_size + center

        for i, n in enumerate(G):
            if n in pos:
                pos_arr[i] = np.asarray(pos[n])
    else:
        pos_arr = None
        dom_size = 1

    # obvious layouts
    if len(G) == 0:
        return {}
    if len(G) == 1:
        return {next(iter(G.nodes())): center}

    if pos is not None:
        # Determine size of existing domain to adjust initial positions
        dom_size = max(coord for pos_tup in pos.values() for coord in pos_tup)
        if dom_size == 0:
            dom_size = 1
        pos_arr = seed.rand(len(G), dim) * dom_size + center

        for i, n in enumerate(G):
            if n in pos:
                pos_arr[i] = np.asarray(pos[n])
    else:
        pos_arr = None
        dom_size = 1

    # obvious layouts
    if len(G) == 0:
        return {}
    if len(G) == 1:
        return {next(iter(G.nodes())): center}
    
    # get adjacency matrix
    A = nx.to_scipy_sparse_array(G, dtype="f")

    # algorithm
    try:
        nnodes, _ = A.shape
    except AttributeError as err:
        msg = "fruchterman_reingold() takes an adjacency matrix as input"
        raise nx.NetworkXError(msg) from err

    if pos is None:
        # random initial positions
        pos = np.asarray(seed.rand(nnodes, dim), dtype=A.dtype)
    else:
        # make sure positions are of same type as matrix
        pos = pos.astype(A.dtype)

    # optimal distance between nodes
    if k is None:
        k = np.sqrt(1.0 / nnodes)
    # the initial "temperature"  is about .1 of domain area (=1x1)
    # this is the largest step allowed in the dynamics.
    # We need to calculate this in case our fixed positions force our domain
    # to be much bigger than 1x1
    t = max(max(pos.T[0]) - min(pos.T[0]), max(pos.T[1]) - min(pos.T[1])) * 0.1
    # simple cooling scheme.
    # linearly step down by dt on each iteration so last iteration is size dt.
    dt = t / (iterations + 1)
    delta = np.zeros((pos.shape[0], pos.shape[0], pos.shape[1]), dtype=A.dtype)

    # storing position data
    pos_list = []
    # storing time to generate
    elapsed_time_list = []
    start = time.time()
    # the inscrutable (but fast) version
    # this is still O(V^2)
    # could use multilevel methods to speed this up significantly
    for iteration in range(iterations):
        # matrix of difference between points
        delta = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]
        # distance between points
        distance = np.linalg.norm(delta, axis=-1)
        # enforce minimum distance of 0.01
        np.clip(distance, 0.01, None, out=distance)
        # displacement "force"
        displacement = np.einsum(
            "ijk,ij->ik", delta, (k * k / distance**2 - A * distance / k)
        )
        # update positions
        length = np.linalg.norm(displacement, axis=-1)
        length = np.where(length < 0.01, 0.1, length)
        delta_pos = np.einsum("ij,i->ij", displacement, t / length)
        pos += delta_pos
        # cool temperature
        t -= dt
        # calculate elapsed time and save the data
        curr_time = time.time()
        elapsed_time = (curr_time - start) * 1000 # in ms
        elapsed_time_list.append(elapsed_time)
        pos_list.append(pos)
        if (np.linalg.norm(delta_pos) / nnodes) < threshold:
            break
    # save the pos data to file
    id = G.graph['id']
    type = G.graph['type']
    pos_df = pd.DataFrame({"positions":pos_list,"elapsed_time": elapsed_time_list})
    pos_df.to_csv(f"{POS_FOLDER}/{type}_{id}.csv", index=False)
    return pos, G


def calculate_edge_length_stats(G):
    edge_lengths = []
    for n1, n2 in G.edges:
        x1, y1 = G.nodes[n1]['pos']
        x2, y2 = G.nodes[n1]['pos']
        edge_length = np.sqrt((x1-x2)*(x1-x2) +  (y1-y2)*(y1-y2))
        edge_lengths.append(edge_length)
    
    return {'min': min(edge_lengths),
            'max': max(edge_lengths),
            'avg': sum(edge_lengths)/len(edge_lengths),
            'std': np.std(edge_lengths)}
    

def orientation(p,q,r):
    px, py = p
    qx, qy = q
    rx, ry = r
    val = (qx - px) * (ry - py) - (qy - py) * (rx - px)

    return 1 if val > 0 else -1

def on_segment(p, q, r):
    if q[0] <= max(p[0], r[0]) and q[0] >= min(p[0], r[0]) and q[1] <= max(p[1], r[1]) and q[1] >= min(p[1], r[1]):
        return True
    return False

def check_intersect(v1, v2):
    p1, p2 = v1
    q1, q2 = v2

    o1 = orientation(p1, p2, q1)
    o2 = orientation(p1, p2, q2)
    o3 = orientation(q1, q2, p1)
    o4 = orientation(q1, q2, p2)

    # vectors endpoints on different sides of other vector
    if o1 != o2 and o3 != o4:
        return True

    if o1 == 0 and on_segment(p1, q1, p2):
        return True

    if o2 == 0 and on_segment(p1, q2, p2):
        return True

    if o3 == 0 and on_segment(q1, p1, q2):
        return True

    if o4 == 0 and on_segment(q1, p2, q2):
        return True

    return False
     



def calculate_num_inersections(G):
    num_intersections = 0
    for e1, e2 in combinations(G.edges, 2):
        if check_intersect(e1, e2):
            num_intersections = num_intersections + 1
    
    return num_intersections

